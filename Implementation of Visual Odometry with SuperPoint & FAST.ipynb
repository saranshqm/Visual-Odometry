{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sp_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "\n",
    "\n",
    "class SuperPointNet(torch.nn.Module):\n",
    "    \"\"\" Pytorch definition of SuperPoint Network. \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SuperPointNet, self).__init__()\n",
    "        self.relu = torch.nn.ReLU(inplace=True)\n",
    "        self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        c1, c2, c3, c4, c5, d1 = 64, 64, 128, 128, 256, 256\n",
    "        # Shared Encoder.\n",
    "        self.conv1a = torch.nn.Conv2d(\n",
    "            1, c1, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv1b = torch.nn.Conv2d(\n",
    "            c1, c1, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2a = torch.nn.Conv2d(\n",
    "            c1, c2, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2b = torch.nn.Conv2d(\n",
    "            c2, c2, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3a = torch.nn.Conv2d(\n",
    "            c2, c3, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3b = torch.nn.Conv2d(\n",
    "            c3, c3, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4a = torch.nn.Conv2d(\n",
    "            c3, c4, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4b = torch.nn.Conv2d(\n",
    "            c4, c4, kernel_size=3, stride=1, padding=1)\n",
    "        # Detector Head.\n",
    "        self.convPa = torch.nn.Conv2d(\n",
    "            c4, c5, kernel_size=3, stride=1, padding=1)\n",
    "        self.convPb = torch.nn.Conv2d(\n",
    "            c5, 65, kernel_size=1, stride=1, padding=0)\n",
    "        # Descriptor Head.\n",
    "        self.convDa = torch.nn.Conv2d(\n",
    "            c4, c5, kernel_size=3, stride=1, padding=1)\n",
    "        self.convDb = torch.nn.Conv2d(\n",
    "            c5, d1, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\" Forward pass that jointly computes unprocessed point and descriptor\n",
    "        tensors.\n",
    "        Input\n",
    "          x: Image pytorch tensor shaped N x 1 x H x W.\n",
    "        Output\n",
    "          semi: Output point pytorch tensor shaped N x 65 x H/8 x W/8.\n",
    "          desc: Output descriptor pytorch tensor shaped N x 256 x H/8 x W/8.\n",
    "        \"\"\"\n",
    "        # Shared Encoder.\n",
    "        x = self.relu(self.conv1a(x))\n",
    "        x = self.relu(self.conv1b(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2a(x))\n",
    "        x = self.relu(self.conv2b(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv3a(x))\n",
    "        x = self.relu(self.conv3b(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv4a(x))\n",
    "        x = self.relu(self.conv4b(x))\n",
    "        # Detector Head.\n",
    "        cPa = self.relu(self.convPa(x))\n",
    "        semi = self.convPb(cPa)\n",
    "        # Descriptor Head.\n",
    "        cDa = self.relu(self.convDa(x))\n",
    "        desc = self.convDb(cDa)\n",
    "        dn = torch.norm(desc, p=2, dim=1)  # Compute the norm.\n",
    "        desc = desc.div(torch.unsqueeze(dn, 1))  # Divide by norm to normalize.\n",
    "        return semi, desc\n",
    "\n",
    "\n",
    "class SuperPointFrontend(object):\n",
    "    \"\"\" Wrapper around pytorch net to help with pre and post image processing. \"\"\"\n",
    "\n",
    "    def __init__(self, weights_path, nms_dist, conf_thresh, nn_thresh,\n",
    "                 cuda=False):\n",
    "        self.name = 'SuperPoint'\n",
    "        self.cuda = cuda\n",
    "        self.nms_dist = nms_dist\n",
    "        self.conf_thresh = conf_thresh\n",
    "        self.nn_thresh = nn_thresh  # L2 descriptor distance for good match.\n",
    "        self.cell = 8  # Size of each output cell. Keep this fixed.\n",
    "        self.border_remove = 4  # Remove points this close to the border.\n",
    "\n",
    "        # Load the network in inference mode.\n",
    "        self.net = SuperPointNet()\n",
    "        if cuda:\n",
    "            # Train on GPU, deploy on GPU.\n",
    "            self.net.load_state_dict(torch.load(weights_path))\n",
    "            self.net = self.net.cuda()\n",
    "        else:\n",
    "            # Train on GPU, deploy on CPU.\n",
    "            self.net.load_state_dict(torch.load(weights_path,\n",
    "                                                map_location=lambda storage, loc: storage))\n",
    "        self.net.eval()\n",
    "\n",
    "    def nms_fast(self, in_corners, H, W, dist_thresh):\n",
    "        \"\"\"\n",
    "        Run a faster approximate Non-Max-Suppression on numpy corners shaped:\n",
    "          3xN [x_i,y_i,conf_i]^T\n",
    "        Algo summary: Create a grid sized HxW. Assign each corner location a 1, rest\n",
    "        are zeros. Iterate through all the 1's and convert them either to -1 or 0.\n",
    "        Suppress points by setting nearby values to 0.\n",
    "        Grid Value Legend:\n",
    "        -1 : Kept.\n",
    "         0 : Empty or suppressed.\n",
    "         1 : To be processed (converted to either kept or supressed).\n",
    "        NOTE: The NMS first rounds points to integers, so NMS distance might not\n",
    "        be exactly dist_thresh. It also assumes points are within image boundaries.\n",
    "        Inputs\n",
    "          in_corners - 3xN numpy array with corners [x_i, y_i, confidence_i]^T.\n",
    "          H - Image height.\n",
    "          W - Image width.\n",
    "          dist_thresh - Distance to suppress, measured as an infinty norm distance.\n",
    "        Returns\n",
    "          nmsed_corners - 3xN numpy matrix with surviving corners.\n",
    "          nmsed_inds - N length numpy vector with surviving corner indices.\n",
    "        \"\"\"\n",
    "        grid = np.zeros((H, W)).astype(int)  # Track NMS data.\n",
    "        inds = np.zeros((H, W)).astype(int)  # Store indices of points.\n",
    "        # Sort by confidence and round to nearest int.\n",
    "        inds1 = np.argsort(-in_corners[2, :])\n",
    "        corners = in_corners[:, inds1]\n",
    "        rcorners = corners[:2, :].round().astype(int)  # Rounded corners.\n",
    "        # Check for edge case of 0 or 1 corners.\n",
    "        if rcorners.shape[1] == 0:\n",
    "            return np.zeros((3, 0)).astype(int), np.zeros(0).astype(int)\n",
    "        if rcorners.shape[1] == 1:\n",
    "            out = np.vstack((rcorners, in_corners[2])).reshape(3, 1)\n",
    "            return out, np.zeros((1)).astype(int)\n",
    "        # Initialize the grid.\n",
    "        for i, rc in enumerate(rcorners.T):\n",
    "            grid[rcorners[1, i], rcorners[0, i]] = 1\n",
    "            inds[rcorners[1, i], rcorners[0, i]] = i\n",
    "        # Pad the border of the grid, so that we can NMS points near the border.\n",
    "        pad = dist_thresh\n",
    "        grid = np.pad(grid, ((pad, pad), (pad, pad)), mode='constant')\n",
    "        # Iterate through points, highest to lowest conf, suppress neighborhood.\n",
    "        count = 0\n",
    "        for i, rc in enumerate(rcorners.T):\n",
    "            # Account for top and left padding.\n",
    "            pt = (rc[0] + pad, rc[1] + pad)\n",
    "            if grid[pt[1], pt[0]] == 1:  # If not yet suppressed.\n",
    "                grid[pt[1] - pad:pt[1] + pad + 1,\n",
    "                     pt[0] - pad:pt[0] + pad + 1] = 0\n",
    "                grid[pt[1], pt[0]] = -1\n",
    "                count += 1\n",
    "        # Get all surviving -1's and return sorted array of remaining corners.\n",
    "        keepy, keepx = np.where(grid == -1)\n",
    "        keepy, keepx = keepy - pad, keepx - pad\n",
    "        inds_keep = inds[keepy, keepx]\n",
    "        out = corners[:, inds_keep]\n",
    "        values = out[-1, :]\n",
    "        inds2 = np.argsort(-values)\n",
    "        out = out[:, inds2]\n",
    "        out_inds = inds1[inds_keep[inds2]]\n",
    "        return out, out_inds\n",
    "\n",
    "    def run(self, img):\n",
    "        \"\"\" Process a numpy image to extract points and descriptors.\n",
    "        Input\n",
    "          img - HxW numpy float32 input image in range [0,1].\n",
    "        Output\n",
    "          corners - 3xN numpy array with corners [x_i, y_i, confidence_i]^T.\n",
    "          desc - 256xN numpy array of corresponding unit normalized descriptors.\n",
    "          heatmap - HxW numpy heatmap in range [0,1] of point confidences.\n",
    "          \"\"\"\n",
    "        # === convert image =========================\n",
    "        if img.ndim != 2:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        if img.dtype != np.float32:\n",
    "            img = img.astype('float32')\n",
    "        if np.max(img) > 1.0:\n",
    "            img = img / 255.0\n",
    "        # ===========================================\n",
    "\n",
    "        assert img.ndim == 2, 'Image must be grayscale.'\n",
    "        assert img.dtype == np.float32, 'Image must be float32.'\n",
    "        H, W = img.shape[0], img.shape[1]\n",
    "        inp = img.copy()\n",
    "        inp = (inp.reshape(1, H, W))\n",
    "        inp = torch.from_numpy(inp)\n",
    "        inp = torch.autograd.Variable(inp).view(1, 1, H, W)\n",
    "        if self.cuda:\n",
    "            inp = inp.cuda()\n",
    "        # Forward pass of network.\n",
    "        outs = self.net.forward(inp)\n",
    "        semi, coarse_desc = outs[0], outs[1]\n",
    "        # Convert pytorch -> numpy.\n",
    "        semi = semi.data.cpu().numpy().squeeze()\n",
    "        # --- Process points.\n",
    "        dense = np.exp(semi)  # Softmax.\n",
    "        dense = dense / (np.sum(dense, axis=0) + .00001)  # Should sum to 1.\n",
    "        # Remove dustbin.\n",
    "        nodust = dense[:-1, :, :]\n",
    "        # Reshape to get full resolution heatmap.\n",
    "        Hc = int(H / self.cell)\n",
    "        Wc = int(W / self.cell)\n",
    "        nodust = nodust.transpose(1, 2, 0)\n",
    "        heatmap = np.reshape(nodust, [Hc, Wc, self.cell, self.cell])\n",
    "        heatmap = np.transpose(heatmap, [0, 2, 1, 3])\n",
    "        heatmap = np.reshape(heatmap, [Hc * self.cell, Wc * self.cell])\n",
    "        xs, ys = np.where(heatmap >= self.conf_thresh)  # Confidence threshold.\n",
    "        if len(xs) == 0:\n",
    "            return np.zeros((3, 0)), None, None\n",
    "        pts = np.zeros((3, len(xs)))  # Populate point data sized 3xN.\n",
    "        pts[0, :] = ys\n",
    "        pts[1, :] = xs\n",
    "        pts[2, :] = heatmap[xs, ys]\n",
    "        # Apply NMS.\n",
    "        pts, _ = self.nms_fast(pts, H, W, dist_thresh=self.nms_dist)\n",
    "        inds = np.argsort(pts[2, :])\n",
    "        pts = pts[:, inds[::-1]]  # Sort by confidence.\n",
    "        # Remove points along border.\n",
    "        bord = self.border_remove\n",
    "        toremoveW = np.logical_or(pts[0, :] < bord, pts[0, :] >= (W - bord))\n",
    "        toremoveH = np.logical_or(pts[1, :] < bord, pts[1, :] >= (H - bord))\n",
    "        toremove = np.logical_or(toremoveW, toremoveH)\n",
    "        pts = pts[:, ~toremove]\n",
    "        # --- Process descriptor.\n",
    "        D = coarse_desc.shape[1]\n",
    "        if pts.shape[1] == 0:\n",
    "            desc = np.zeros((D, 0))\n",
    "        else:\n",
    "            # Interpolate into descriptor map using 2D point locations.\n",
    "            samp_pts = torch.from_numpy(pts[:2, :].copy())\n",
    "            samp_pts[0, :] = (samp_pts[0, :] / (float(W) / 2.)) - 1.\n",
    "            samp_pts[1, :] = (samp_pts[1, :] / (float(H) / 2.)) - 1.\n",
    "            samp_pts = samp_pts.transpose(0, 1).contiguous()\n",
    "            samp_pts = samp_pts.view(1, 1, -1, 2)\n",
    "            samp_pts = samp_pts.float()\n",
    "            if self.cuda:\n",
    "                samp_pts = samp_pts.cuda()\n",
    "            desc = torch.nn.functional.grid_sample(coarse_desc, samp_pts)\n",
    "            desc = desc.data.cpu().numpy().reshape(D, -1)\n",
    "            desc /= np.linalg.norm(desc, axis=0)[np.newaxis, :]\n",
    "        return pts, desc, heatmap\n",
    "\n",
    "\n",
    "class PointTracker(object):\n",
    "    \"\"\" Class to manage a fixed memory of points and descriptors that enables\n",
    "    sparse optical flow point tracking.\n",
    "    Internally, the tracker stores a 'tracks' matrix sized M x (2+L), of M\n",
    "    tracks with maximum length L, where each row corresponds to:\n",
    "    row_m = [track_id_m, avg_desc_score_m, point_id_0_m, ..., point_id_L-1_m].\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, max_length, nn_thresh):\n",
    "        if max_length < 2:\n",
    "            raise ValueError('max_length must be greater than or equal to 2.')\n",
    "        self.maxl = max_length\n",
    "        self.nn_thresh = nn_thresh\n",
    "        self.all_pts = []\n",
    "        for n in range(self.maxl):\n",
    "            self.all_pts.append(np.zeros((2, 0)))\n",
    "        self.last_desc = None\n",
    "        self.tracks = np.zeros((0, self.maxl + 2))\n",
    "        self.track_count = 0\n",
    "        self.max_score = 9999\n",
    "\n",
    "    def nn_match_two_way(self, desc1, desc2, nn_thresh):\n",
    "        \"\"\"\n",
    "        Performs two-way nearest neighbor matching of two sets of descriptors, such\n",
    "        that the NN match from descriptor A->B must equal the NN match from B->A.\n",
    "        Inputs:\n",
    "          desc1 - NxM numpy matrix of N corresponding M-dimensional descriptors.\n",
    "          desc2 - NxM numpy matrix of N corresponding M-dimensional descriptors.\n",
    "          nn_thresh - Optional descriptor distance below which is a good match.\n",
    "        Returns:\n",
    "          matches - 3xL numpy array, of L matches, where L <= N and each column i is\n",
    "                    a match of two descriptors, d_i in image 1 and d_j' in image 2:\n",
    "                    [d_i index, d_j' index, match_score]^T\n",
    "        \"\"\"\n",
    "        assert desc1.shape[0] == desc2.shape[0]\n",
    "        if desc1.shape[1] == 0 or desc2.shape[1] == 0:\n",
    "            return np.zeros((3, 0))\n",
    "        if nn_thresh < 0.0:\n",
    "            raise ValueError('\\'nn_thresh\\' should be non-negative')\n",
    "        # Compute L2 distance. Easy since vectors are unit normalized.\n",
    "        dmat = np.dot(desc1.T, desc2)\n",
    "        dmat = np.sqrt(2 - 2 * np.clip(dmat, -1, 1))\n",
    "        # Get NN indices and scores.\n",
    "        idx = np.argmin(dmat, axis=1)\n",
    "        scores = dmat[np.arange(dmat.shape[0]), idx]\n",
    "        # Threshold the NN matches.\n",
    "        keep = scores < nn_thresh\n",
    "        # Check if nearest neighbor goes both directions and keep those.\n",
    "        idx2 = np.argmin(dmat, axis=0)\n",
    "        keep_bi = np.arange(len(idx)) == idx2[idx]\n",
    "        keep = np.logical_and(keep, keep_bi)\n",
    "        idx = idx[keep]\n",
    "        scores = scores[keep]\n",
    "        # Get the surviving point indices.\n",
    "        m_idx1 = np.arange(desc1.shape[1])[keep]\n",
    "        m_idx2 = idx\n",
    "        # Populate the final 3xN match data structure.\n",
    "        matches = np.zeros((3, int(keep.sum())))\n",
    "        matches[0, :] = m_idx1\n",
    "        matches[1, :] = m_idx2\n",
    "        matches[2, :] = scores\n",
    "        return matches\n",
    "\n",
    "    def get_offsets(self):\n",
    "        \"\"\" Iterate through list of points and accumulate an offset value. Used to\n",
    "        index the global point IDs into the list of points.\n",
    "        Returns\n",
    "          offsets - N length array with integer offset locations.\n",
    "        \"\"\"\n",
    "        # Compute id offsets.\n",
    "        offsets = []\n",
    "        offsets.append(0)\n",
    "        # Skip last camera size, not needed.\n",
    "        for i in range(len(self.all_pts) - 1):\n",
    "            offsets.append(self.all_pts[i].shape[1])\n",
    "        offsets = np.array(offsets)\n",
    "        offsets = np.cumsum(offsets)\n",
    "        return offsets\n",
    "\n",
    "    def update(self, pts, desc):\n",
    "        \"\"\" Add a new set of point and descriptor observations to the tracker.\n",
    "        Inputs\n",
    "          pts - 3xN numpy array of 2D point observations.\n",
    "          desc - DxN numpy array of corresponding D dimensional descriptors.\n",
    "        \"\"\"\n",
    "        if pts is None or desc is None:\n",
    "            print('PointTracker: Warning, no points were added to tracker.')\n",
    "            return\n",
    "        assert pts.shape[1] == desc.shape[1]\n",
    "        # Initialize last_desc.\n",
    "        if self.last_desc is None:\n",
    "            self.last_desc = np.zeros((desc.shape[0], 0))\n",
    "        # Remove oldest points, store its size to update ids later.\n",
    "        remove_size = self.all_pts[0].shape[1]\n",
    "        self.all_pts.pop(0)\n",
    "        self.all_pts.append(pts)\n",
    "        # Remove oldest point in track.\n",
    "        self.tracks = np.delete(self.tracks, 2, axis=1)\n",
    "        # Update track offsets.\n",
    "        for i in range(2, self.tracks.shape[1]):\n",
    "            self.tracks[:, i] -= remove_size\n",
    "        self.tracks[:, 2:][self.tracks[:, 2:] < -1] = -1\n",
    "        offsets = self.get_offsets()\n",
    "        # Add a new -1 column.\n",
    "        self.tracks = np.hstack(\n",
    "            (self.tracks, -1 * np.ones((self.tracks.shape[0], 1))))\n",
    "        # Try to append to existing tracks.\n",
    "        matched = np.zeros((pts.shape[1])).astype(bool)\n",
    "        matches = self.nn_match_two_way(self.last_desc, desc, self.nn_thresh)\n",
    "        for match in matches.T:\n",
    "            # Add a new point to it's matched track.\n",
    "            id1 = int(match[0]) + offsets[-2]\n",
    "            id2 = int(match[1]) + offsets[-1]\n",
    "            found = np.argwhere(self.tracks[:, -2] == id1)\n",
    "            if found.shape[0] > 0:\n",
    "                matched[int(match[1])] = True\n",
    "                row = int(found)\n",
    "                self.tracks[row, -1] = id2\n",
    "                if self.tracks[row, 1] == self.max_score:\n",
    "                    # Initialize track score.\n",
    "                    self.tracks[row, 1] = match[2]\n",
    "                else:\n",
    "                    # Update track score with running average.\n",
    "                    # NOTE(dd): this running average can contain scores from old matches\n",
    "                    #           not contained in last max_length track points.\n",
    "                    track_len = (self.tracks[row, 2:] != -1).sum() - 1.\n",
    "                    frac = 1. / float(track_len)\n",
    "                    self.tracks[row, 1] = (1. - frac) * \\\n",
    "                        self.tracks[row, 1] + frac * match[2]\n",
    "        # Add unmatched tracks.\n",
    "        new_ids = np.arange(pts.shape[1]) + offsets[-1]\n",
    "        new_ids = new_ids[~matched]\n",
    "        new_tracks = -1 * np.ones((new_ids.shape[0], self.maxl + 2))\n",
    "        new_tracks[:, -1] = new_ids\n",
    "        new_num = new_ids.shape[0]\n",
    "        new_trackids = self.track_count + np.arange(new_num)\n",
    "        new_tracks[:, 0] = new_trackids\n",
    "        new_tracks[:, 1] = self.max_score * np.ones(new_ids.shape[0])\n",
    "        self.tracks = np.vstack((self.tracks, new_tracks))\n",
    "        self.track_count += new_num  # Update the track count.\n",
    "        # Remove empty tracks.\n",
    "        keep_rows = np.any(self.tracks[:, 2:] >= 0, axis=1)\n",
    "        self.tracks = self.tracks[keep_rows, :]\n",
    "        # Store the last descriptors.\n",
    "        self.last_desc = desc.copy()\n",
    "        return\n",
    "\n",
    "    def get_tracks(self, min_length):\n",
    "        \"\"\" Retrieve point tracks of a given minimum length.\n",
    "        Input\n",
    "          min_length - integer >= 1 with minimum track length\n",
    "        Output\n",
    "          returned_tracks - M x (2+L) sized matrix storing track indices, where\n",
    "            M is the number of tracks and L is the maximum track length.\n",
    "        \"\"\"\n",
    "        if min_length < 1:\n",
    "            raise ValueError('\\'min_length\\' too small.')\n",
    "        valid = np.ones((self.tracks.shape[0])).astype(bool)\n",
    "        good_len = np.sum(self.tracks[:, 2:] != -1, axis=1) >= min_length\n",
    "        # Remove tracks which do not have an observation in most recent frame.\n",
    "        not_headless = (self.tracks[:, -1] != -1)\n",
    "        keepers = np.logical_and.reduce((valid, good_len, not_headless))\n",
    "        returned_tracks = self.tracks[keepers, :].copy()\n",
    "        return returned_tracks\n",
    "\n",
    "    def draw_tracks(self, tracks):\n",
    "        \"\"\" Visualize tracks all overlayed on a single image.\n",
    "        Inputs\n",
    "          tracks - M x (2+L) sized matrix storing track info.\n",
    "        \"\"\"\n",
    "        # Store the number of points per camera.\n",
    "        pts_mem = self.all_pts\n",
    "        N = len(pts_mem)  # Number of cameras/images.\n",
    "        # Get offset ids needed to reference into pts_mem.\n",
    "        offsets = self.get_offsets()\n",
    "\n",
    "        kp1 = []\n",
    "        kp2 = []\n",
    "        # Iterate through each track and draw it.\n",
    "        for track in tracks:\n",
    "            for i in range(N - 1):\n",
    "                if track[i + 2] == -1 or track[i + 3] == -1:\n",
    "                    continue\n",
    "                offset1 = offsets[i]\n",
    "                offset2 = offsets[i + 1]\n",
    "                idx1 = int(track[i + 2] - offset1)\n",
    "                idx2 = int(track[i + 3] - offset2)\n",
    "                pt1 = pts_mem[i][:2, idx1]\n",
    "                pt2 = pts_mem[i + 1][:2, idx2]\n",
    "                p1 = [int(round(pt1[0])), int(round(pt1[1]))]\n",
    "                p2 = [int(round(pt2[0])), int(round(pt2[1]))]\n",
    "                kp1.append(p1)\n",
    "                kp2.append(p2)\n",
    "        return np.array(kp1), np.array(kp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "norm_visual_odometry.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "STAGE_FIRST_FRAME = 0\n",
    "STAGE_SECOND_FRAME = 1\n",
    "STAGE_DEFAULT_FRAME = 2\n",
    "kMinNumFeature = 500\n",
    "\n",
    "lk_params = dict(winSize=(21, 21),\n",
    "                 #maxLevel = 3,\n",
    "                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 30, 0.01))\n",
    "\n",
    "\n",
    "def featureTracking(image_ref, image_cur, px_ref):\n",
    "    kp2, st, err = cv2.calcOpticalFlowPyrLK(\n",
    "        image_ref, image_cur, px_ref, None, **lk_params)  # shape: [k,2] [k,1] [k,1]\n",
    "\n",
    "    st = st.reshape(st.shape[0])\n",
    "    kp1 = px_ref[st == 1]\n",
    "    kp2 = kp2[st == 1]\n",
    "\n",
    "    return kp1, kp2\n",
    "\n",
    "\n",
    "class PinholeCamera:\n",
    "    def __init__(self, width, height, fx, fy, cx, cy,\n",
    "                 k1=0.0, k2=0.0, p1=0.0, p2=0.0, k3=0.0):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.fx = fx\n",
    "        self.fy = fy\n",
    "        self.cx = cx\n",
    "        self.cy = cy\n",
    "        self.distortion = (abs(k1) > 0.0000001)\n",
    "        self.d = [k1, k2, p1, p2, k3]\n",
    "\n",
    "\n",
    "class VisualOdometry_fast:\n",
    "    def __init__(self, cam):\n",
    "        self.frame_stage = 0\n",
    "        self.cam = cam\n",
    "        self.new_frame = None\n",
    "        self.last_frame = None\n",
    "        self.cur_R = None\n",
    "        self.cur_t = None\n",
    "        self.px_ref = None\n",
    "        self.px_cur = None\n",
    "        self.focal = cam.fx\n",
    "        self.pp = (cam.cx, cam.cy)\n",
    "        self.trueX, self.trueY, self.trueZ = 0, 0, 0\n",
    "        self.detector = cv2.FastFeatureDetector_create(threshold=100,\n",
    "                                                       nonmaxSuppression=True)\n",
    "    def getAbsoluteScale(self, frame_id): \n",
    "        \"\"\"\n",
    "        ss = self.annotations[frame_id - 1].strip().split()\n",
    "        x_prev = float(ss[3])\n",
    "        y_prev = float(ss[7])\n",
    "        z_prev = float(ss[11])\n",
    "        ss = self.annotations[frame_id].strip().split()\n",
    "        x = float(ss[3])\n",
    "        y = float(ss[7])\n",
    "        z = float(ss[11])\n",
    "        self.trueX, self.trueY, self.trueZ = x, y, z\n",
    "        return np.sqrt((x - x_prev) * (x - x_prev) + (y - y_prev) * (y - y_prev) + (z - z_prev) * (z - z_prev))\n",
    "        \"\"\"\n",
    "        return 2\n",
    "\n",
    "    def processFirstFrame(self):\n",
    "        self.px_ref = self.detector.detect(self.new_frame)\n",
    "        self.px_ref = np.array([x.pt for x in self.px_ref], dtype=np.float32)\n",
    "        self.frame_stage = STAGE_SECOND_FRAME\n",
    "\n",
    "    def processSecondFrame(self):\n",
    "        self.px_ref, self.px_cur = featureTracking(self.last_frame, self.new_frame,\n",
    "                                                   self.px_ref)\n",
    "        E, mask = cv2.findEssentialMat(self.px_cur, self.px_ref,\n",
    "                                       focal=self.focal, pp=self.pp,\n",
    "                                       method=cv2.RANSAC, prob=0.999, threshold=1.0)\n",
    "        _, self.cur_R, self.cur_t, mask = cv2.recoverPose(E, self.px_cur, self.px_ref,\n",
    "                                                          focal=self.focal, pp=self.pp)\n",
    "        self.frame_stage = STAGE_DEFAULT_FRAME\n",
    "        self.px_ref = self.px_cur\n",
    "\n",
    "    def processFrame(self, frame_id):\n",
    "        self.px_ref, self.px_cur = featureTracking(self.last_frame, self.new_frame,\n",
    "                                                   self.px_ref)\n",
    "        E, mask = cv2.findEssentialMat(self.px_cur, self.px_ref,\n",
    "                                       focal=self.focal, pp=self.pp,\n",
    "                                       method=cv2.RANSAC, prob=0.999, threshold=1.0)\n",
    "        _, R, t, mask = cv2.recoverPose(E, self.px_cur, self.px_ref,\n",
    "                                        focal=self.focal, pp=self.pp)\n",
    "        absolute_scale = self.getAbsoluteScale(frame_id)\n",
    "        if(absolute_scale > 0.1):\n",
    "            self.cur_t = self.cur_t + absolute_scale * self.cur_R.dot(t)\n",
    "            self.cur_R = R.dot(self.cur_R)\n",
    "        if(self.px_ref.shape[0] < kMinNumFeature):\n",
    "            self.px_cur = self.detector.detect(self.new_frame)\n",
    "            self.px_cur = np.array(\n",
    "                [x.pt for x in self.px_cur], dtype=np.float32)\n",
    "        self.px_ref = self.px_cur\n",
    "\n",
    "    def update(self, img, frame_id):\n",
    "        self.new_frame = img\n",
    "        if(self.frame_stage == STAGE_DEFAULT_FRAME):\n",
    "            self.processFrame(frame_id)\n",
    "        elif(self.frame_stage == STAGE_SECOND_FRAME):\n",
    "            self.processSecondFrame()\n",
    "        elif(self.frame_stage == STAGE_FIRST_FRAME):\n",
    "            self.processFirstFrame()\n",
    "        self.last_frame = self.new_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SP_visual odometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "STAGE_FIRST_FRAME = 0\n",
    "STAGE_SECOND_FRAME = 1\n",
    "STAGE_DEFAULT_FRAME = 2\n",
    "\n",
    "\n",
    "class PinholeCamera:\n",
    "    def __init__(self, width, height, fx, fy, cx, cy,\n",
    "                 k1=0.0, k2=0.0, p1=0.0, p2=0.0, k3=0.0):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.fx = fx\n",
    "        self.fy = fy\n",
    "        self.cx = cx\n",
    "        self.cy = cy\n",
    "        self.distortion = (abs(k1) > 0.0000001)\n",
    "        self.d = [k1, k2, p1, p2, k3]\n",
    "\n",
    "\n",
    "class VisualOdometry:\n",
    "    def __init__(self, cam):\n",
    "        self.frame_stage = 0\n",
    "        self.cam = cam\n",
    "        self.new_frame = None\n",
    "        self.last_frame = None\n",
    "        self.cur_R = None\n",
    "        self.cur_t = None\n",
    "        self.px_ref = None\n",
    "        self.px_cur = None\n",
    "        self.focal = cam.fx\n",
    "        self.pp = (cam.cx, cam.cy)\n",
    "        self.trueX, self.trueY, self.trueZ = 0, 0, 0\n",
    "        \n",
    "        \n",
    "        \n",
    "        ############################ LOAD superpoint_v1.pth here ###################################################\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.detector = SuperPointFrontend(weights_path=\"D:/Swayatt Robots/work/work done/superPoint/trained_weights/superpoint_v1.pth\",\n",
    "                                           nms_dist=4,\n",
    "                                           conf_thresh=0.015,\n",
    "                                           nn_thresh=0.7,\n",
    "                                           cuda=True)\n",
    "        \n",
    "        \n",
    "        ##################### Increase max_length from 2 to increase the length of point tracking\n",
    "        max_length = 2  #### this parameter should be >=2\n",
    "        \n",
    "        self.tracker = PointTracker(\n",
    "            max_length=max_length, nn_thresh=self.detector.nn_thresh)\n",
    "         \n",
    "\n",
    "\n",
    "\n",
    "    def featureTracking(self):\n",
    "        pts, desc, heatmap = self.detector.run(self.new_frame)\n",
    "        # Add points and descriptors to the tracker.\n",
    "        self.tracker.update(pts, desc)\n",
    "        # Get tracks for points which were match successfully across all frames.\n",
    "        tracks = self.tracker.get_tracks(min_length=1)\n",
    "        # Normalize track scores to [0,1].\n",
    "        tracks[:, 1] /= float(self.detector.nn_thresh)\n",
    "        kp1, kp2 = self.tracker.draw_tracks(tracks)\n",
    "        return kp1, kp2\n",
    "\n",
    "    def getAbsoluteScale(self, frame_id):  # specialized for KITTI odometry dataset\n",
    "        \"\"\"\n",
    "        ss = self.annotations[frame_id - 1].strip().split()\n",
    "        x_prev = float(ss[3])\n",
    "        y_prev = float(ss[7])\n",
    "        z_prev = float(ss[11])\n",
    "        ss = self.annotations[frame_id].strip().split()\n",
    "        x = float(ss[3])\n",
    "        y = float(ss[7])\n",
    "        z = float(ss[11])\n",
    "        self.trueX, self.trueY, self.trueZ = x, y, z\n",
    "        return np.sqrt((x - x_prev) * (x - x_prev) + (y - y_prev) * (y - y_prev) + (z - z_prev) * (z - z_prev))\n",
    "        \"\"\"\n",
    "        return 2\n",
    "    \n",
    "    def processFirstFrame(self):\n",
    "        self.px_ref, self.px_cur = self.featureTracking()\n",
    "        self.frame_stage = STAGE_SECOND_FRAME\n",
    "\n",
    "    def processSecondFrame(self):\n",
    "        self.px_ref, self.px_cur = self.featureTracking()\n",
    "\n",
    "        E, mask = cv2.findEssentialMat(self.px_cur, self.px_ref,\n",
    "                                       focal=self.focal, pp=self.pp,\n",
    "                                       method=cv2.RANSAC, prob=0.999, threshold=1.0)\n",
    "        _, self.cur_R, self.cur_t, mask = cv2.recoverPose(E, self.px_cur, self.px_ref,\n",
    "                                                          focal=self.focal, pp=self.pp)\n",
    "        self.frame_stage = STAGE_DEFAULT_FRAME\n",
    "        self.px_ref = self.px_cur\n",
    "\n",
    "    def processFrame(self, frame_id):\n",
    "        self.px_ref, self.px_cur = self.featureTracking()\n",
    "\n",
    "        E, mask = cv2.findEssentialMat(self.px_cur, self.px_ref,\n",
    "                                       focal=self.focal, pp=self.pp,\n",
    "                                       method=cv2.RANSAC, prob=0.999, threshold=1.0)\n",
    "        _, R, t, mask = cv2.recoverPose(E, self.px_cur, self.px_ref,\n",
    "                                        focal=self.focal, pp=self.pp)\n",
    "        absolute_scale = self.getAbsoluteScale(frame_id)\n",
    "        if(absolute_scale > 0.1):\n",
    "            self.cur_t = self.cur_t + absolute_scale * self.cur_R.dot(t)\n",
    "            self.cur_R = R.dot(self.cur_R)\n",
    "        self.px_ref = self.px_cur\n",
    "\n",
    "    def update(self, img, frame_id):\n",
    "        #assert(img.ndim == 2 and img.shape[0] == self.cam.height and img.shape[1] == self.cam.width), \"Frame: provided image has not the same size as the camera model or image is not grayscale\"\n",
    "        self.new_frame = img\n",
    "        if(self.frame_stage == STAGE_DEFAULT_FRAME):\n",
    "            self.processFrame(frame_id)\n",
    "        elif(self.frame_stage == STAGE_SECOND_FRAME):\n",
    "            self.processSecondFrame()\n",
    "        elif(self.frame_stage == STAGE_FIRST_FRAME):\n",
    "            self.processFirstFrame()\n",
    "        self.last_frame = self.new_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARANSH\\Anaconda3\\envs\\saransh\\lib\\site-packages\\torch\\nn\\functional.py:3226: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "cam4 = PinholeCamera(1280.0, 376.0, 720, 720, 607.1928, 185.2157)\n",
    "\n",
    "vo = VisualOdometry_fast(cam4)\n",
    "sp_vo = VisualOdometry(cam4)\n",
    "\n",
    "traj = np.zeros((1200, 1200, 3), dtype=np.uint8)\n",
    "\n",
    "sp_errors = []\n",
    "norm_errors = []\n",
    "sp_feature_nums = []\n",
    "norm_feature_nums = []\n",
    "\n",
    "from os.path import isfile, join\n",
    "\n",
    "\n",
    "\n",
    "############# LOAD IMAGES HERE\n",
    "image_folder='.'\n",
    "os.chdir(\"D:/Swayatt Robots/work/work done/dataSets/new data/saransh/annotated images\") \n",
    "\n",
    "\n",
    "\n",
    "files = [f for f in os.listdir(image_folder) if isfile(join(image_folder, f))]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for sorting the file names properly\n",
    "# x[:-4] depends upon the image name if image name is 0.jpg than x[:-4]\n",
    "files.sort(key = lambda x: int(x[:-4]))     \n",
    "\n",
    "\n",
    "\n",
    "for image in files:\n",
    "    img = cv2.imread(image)\n",
    "    #print(img)\n",
    "    # image[:-4] depends upon the image name if image name is 0.jpg than image[:-4]\n",
    "    img_id = int(image[:-4])\n",
    "    #print(img_id)\n",
    "    #convert to grayscale image\n",
    "    img = cv2.resize(img, (640, 480))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #resize image\n",
    "    \n",
    "    \n",
    "    # === superpoint ==============================\n",
    "    sp_vo.update(img, img_id)\n",
    "\n",
    "    sp_cur_t = sp_vo.cur_t\n",
    "    if(img_id > 2):\n",
    "        sp_x, sp_y, sp_z = sp_cur_t[0], sp_cur_t[1], sp_cur_t[2]\n",
    "    else:\n",
    "        sp_x, sp_y, sp_z = 0., 0., 0.\n",
    "\n",
    "    sp_img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    for (u, v) in sp_vo.px_ref:\n",
    "        cv2.circle(sp_img, (u, v), 3, (0, 255, 0))\n",
    "\n",
    "    # === normal ==================================\n",
    "    vo.update(img, img_id)\n",
    "\n",
    "    cur_t = vo.cur_t\n",
    "    if(img_id > 2):\n",
    "        x, y, z = cur_t[0], cur_t[1], cur_t[2]\n",
    "    else:\n",
    "        x, y, z = 0., 0., 0.\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    for (u, v) in vo.px_ref:\n",
    "        cv2.circle(img, (u, v), 3, (0, 255, 0))\n",
    "\n",
    "    # === calculation =============================\n",
    "    # calculate error\n",
    "    sp_est_point = np.array([sp_x, sp_z]).reshape(2)\n",
    "    norm_est_point = np.array([x, z]).reshape(2)\n",
    "    gt_point = np.array([sp_vo.trueX, sp_vo.trueZ]).reshape(2)\n",
    "    sp_error = np.linalg.norm(sp_est_point - gt_point)\n",
    "    norm_error = np.linalg.norm(norm_est_point - gt_point)\n",
    "\n",
    "    # append\n",
    "    sp_errors.append(sp_error)\n",
    "    norm_errors.append(norm_error)\n",
    "    sp_feature_nums.append(len(sp_vo.px_ref))\n",
    "    norm_feature_nums.append(len(vo.px_ref))\n",
    "\n",
    "    # average\n",
    "    avg_sp_error = np.mean(np.array(sp_errors))\n",
    "    avg_norm_error = np.mean(np.array(norm_errors))\n",
    "    avg_sp_feature_num = np.mean(np.array(sp_feature_nums))\n",
    "    avg_norm_feature_num = np.mean(np.array(norm_feature_nums))\n",
    "    \n",
    "    # === drawer ==================================\n",
    "    # each point\n",
    "    sp_draw_x, sp_draw_y = int(sp_x) + 10, int(sp_z) + 200\n",
    "    norm_draw_x, norm_draw_y = int(x) + 10, int(z) + 200\n",
    "    true_x, true_y = int(sp_vo.trueX) + 10, int(sp_vo.trueZ) + 200\n",
    "\n",
    "    # draw trajectory\n",
    "    cv2.circle(traj, (sp_draw_x, sp_draw_y), 1, (255, 0, 0), 1)\n",
    "    cv2.circle(traj, (norm_draw_x, norm_draw_y), 1, (0, 255, 0), 1)\n",
    "    cv2.circle(traj, (true_x, true_y), 1, (0, 0, 255), 2)\n",
    "    cv2.rectangle(traj, (10, 20), (600, 60), (0, 0, 0), -1)\n",
    "    # draw text\n",
    "    text = \"Superpoint: [AvgFeature] %4.2f\" % (\n",
    "       avg_sp_feature_num)\n",
    "    cv2.putText(traj, text, (20, 40),\n",
    "              cv2.FONT_HERSHEY_PLAIN, 1, (255, 0, 0), 1, 8)\n",
    "    text = \"FAST    : [AvgFeature] %4.2f\" % (\n",
    "      avg_norm_feature_num)\n",
    "    cv2.putText(traj, text, (20, 60),\n",
    "              cv2.FONT_HERSHEY_PLAIN, 1, (0, 255, 0), 1, 8)\n",
    "\n",
    "    cv2.imshow('Road facing camera\\n 1. SuperPoint & 2. FAST', np.concatenate((sp_img, img), axis=0))\n",
    "    cv2.imshow('Trajectory', traj)\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "cv2.imwrite('D:/map.jpg', traj)\n",
    "cv2.destroyAllWindows() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
